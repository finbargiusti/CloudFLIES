{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install datasets loralib sentencepiece \n",
    "%pip install bitsandbytes accelerate\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Alpaca 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(\n",
    "    \"chavinlo/alpaca-native\",\n",
    "    # load_in_8bit=True,\n",
    "    device_map='auto',\n",
    "    local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=256,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Chat with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from DBObject import DBObject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "\n",
    "def connect_fun(database_name: str) -> DBObject:\n",
    "  conn = SQLDatabase.from_uri(f\"sqlite:///{database_name}?mode=ro\") # open in readonly mode\n",
    "  return DBObject(db=conn, llm=local_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_fun(question: str, tables: list[str], database_connection: DBObject) -> str:\n",
    "  response = database_connection.make_query(question, tables)\n",
    "\n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot designed to create SQL queries based on a schema, a series of table name hints, and inputs from the user.\n",
      "\n",
      "Schema:\n",
      "\n",
      "CREATE TABLE users (\n",
      "\tid INTEGER, \n",
      "\tname TEXT, \n",
      "\tage INTEGER, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from users table:\n",
      "id\tname\tage\n",
      "1\t7221ea44\t59\n",
      "2\t8dfb994b\t11\n",
      "3\tb5c64f0b\t66\n",
      "*/\n",
      "\n",
      "History: \n",
      "\n",
      "\n",
      "Question: How many users have age over 45? \n",
      "Table name hints: users\n",
      "SQL Query:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " SELECT COUNT(*) FROM users WHERE age > 45;\n"
     ]
    }
   ],
   "source": [
    "# test:\n",
    "\n",
    "connection = connect_fun(\"sampleDatabases/database_10.db\")\n",
    "\n",
    "print(\n",
    "  query_fun(\"How many users have age over 45?\", [\"users\"], connection)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
